{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the 1D CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import context\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "# tf.get_variable('test_bool', 1, tf.bool)\n",
    "from tensorflow.python.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import (Add, Concatenate, Input, Dense, \n",
    "                                            Dropout, Embedding, Conv1D, \n",
    "                                            MaxPooling1D, GlobalAveragePooling1D, \n",
    "                                            Flatten)\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "ROOT_DIR = os.getcwd() + '/'\n",
    "CHECKPOINTS_DIR = ROOT_DIR + 'checkpoints/'\n",
    "construct = context.construct_neural_net\n",
    "encode = context.encode_sequences\n",
    "organize = context.organize_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_filename = ('20190612130111781831_percentiles_els_binarized_homogeneous_deflanked_'\n",
    "                   'sequences_with_exp_levels.txt.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a smaller sample set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_filename = '10000_from_' + sample_filename "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the absolute path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = ROOT_DIR + '../../../example/processed_data/' + sample_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_padded, y_scaled, abs_max_el = encode.encode_sequences_with_method(sample_path, method='One-Hot', scale_els=True, model_type='1DCNN', binarized_els=True)\n",
    "num_seqs, max_sequence_len = organize.get_num_and_len_of_seqs_from_file(sample_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(y_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape expression levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scaled = y_scaled.reshape((len(y_scaled), 1))\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(y_scaled)\n",
    "# y_scaled = scaler.transform(y_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_scaled, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0613 17:17:59.130264 4569744832 callbacks.py:1466] `write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
      "W0613 17:17:59.131922 4569744832 callbacks.py:1469] `batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 78, 15)            240       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 76, 15)            690       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 74, 15)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 72, 15)            690       \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 70, 15)            690       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 2,326\n",
      "Trainable params: 2,326\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the model parameters\n",
    "batch_size = len(y_scaled) * 0.01 # no bigger than 1 % of data\n",
    "filters = 15\n",
    "kernel_size = 3\n",
    "strides = 1\n",
    "epochs = 20\n",
    "dropout = 0.5\n",
    "\n",
    "# Define the tensorboard and checkpointer if desired\n",
    "tb = TensorBoard(log_dir='./logs', \n",
    "                 histogram_freq=3, \n",
    "                 batch_size=batch_size, \n",
    "                 write_graph=True, \n",
    "                 write_grads=True, \n",
    "                 write_images=True)\n",
    "checkpointer = ModelCheckpoint(monitor='val_acc', \n",
    "                               filepath=(CHECKPOINTS_DIR + '1dcnn_sequential_onehot.hdf5'), \n",
    "                               verbose=1, \n",
    "                               save_best_only=True)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Build up the layers\n",
    "model.add(Conv1D(filters, kernel_size, activation='relu', \n",
    "                 input_shape=(max_sequence_len, 5), \n",
    "                 kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "model.add(MaxPooling1D(3, strides))\n",
    "#     keras.layers.Flatten(data_format=None)\n",
    "# model.add(GlobalAveragePooling1D())\n",
    "model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "\n",
    "# Add some dense and dropout layers\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0613 17:18:56.584307 4569744832 callbacks.py:1466] `write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
      "W0613 17:18:56.586462 4569744832 callbacks.py:1469] `batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 80, 5)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 80, 15)       90          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 78, 15)       240         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 76, 15)       390         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 74, 15)       540         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 72, 15)       690         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 70, 15)       840         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 68, 15)       990         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 66, 15)       1140        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 64, 15)       1290        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 62, 15)       1440        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 710, 15)      0           conv1d_14[0][0]                  \n",
      "                                                                 conv1d_15[0][0]                  \n",
      "                                                                 conv1d_16[0][0]                  \n",
      "                                                                 conv1d_17[0][0]                  \n",
      "                                                                 conv1d_18[0][0]                  \n",
      "                                                                 conv1d_19[0][0]                  \n",
      "                                                                 conv1d_20[0][0]                  \n",
      "                                                                 conv1d_21[0][0]                  \n",
      "                                                                 conv1d_22[0][0]                  \n",
      "                                                                 conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 10650)        0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 500)          5325500     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            501         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1)            0           dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,333,651\n",
      "Trainable params: 5,333,651\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the model parameters\n",
    "batch_size = int(len(y_scaled) * 0.01)  # no bigger than 1 % of data\n",
    "filters = 15\n",
    "# kernel_size\n",
    "strides = 1\n",
    "epochs = 10\n",
    "dropout = 0.1\n",
    "num_layers = 10\n",
    "\n",
    "# Define the tensorboard and checkpointer if desired\n",
    "tb = TensorBoard(log_dir='./logs', \n",
    "                 histogram_freq=3, \n",
    "                 batch_size=batch_size, \n",
    "                 write_graph=True, \n",
    "                 write_grads=True, \n",
    "                 write_images=True)\n",
    "checkpointer = ModelCheckpoint(monitor='val_acc', \n",
    "                               filepath=(CHECKPOINTS_DIR + '1dcnn_parallel_onehot.hdf5'), \n",
    "                               verbose=1, \n",
    "                               save_best_only=True)\n",
    "\n",
    "# Define the inputs\n",
    "inputs = Input(shape=(max_sequence_len, 5))\n",
    "layers = []\n",
    "\n",
    "# Build up the layers\n",
    "for i in range(1, num_layers + 1):\n",
    "    layer = Conv1D(filters, (2 * i - 1), strides)(inputs)\n",
    "    layers.append(layer)\n",
    "\n",
    "# Combine the layers\n",
    "combined = Concatenate(axis=1)(layers)\n",
    "\n",
    "# Add some flatten, dense, and dropout layers\n",
    "out = Flatten()(combined)\n",
    "# out = Dropout(dropout)(out)\n",
    "out = Dense(500, activation='sigmoid')(out)\n",
    "out = Dropout(dropout)(out)\n",
    "out = Dense(1, activation='sigmoid')(out)\n",
    "out = Dropout(dropout)(out)\n",
    "\n",
    "# Define the model with inputs and outputs, and compile.\n",
    "model = Model(inputs=inputs, outputs=out)\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0613 18:26:50.170857 4569744832 callbacks.py:1466] `write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
      "W0613 18:26:50.172261 4569744832 callbacks.py:1469] `batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 80, 5)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_127 (Conv1D)             (None, 78, 15)       240         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_128 (Conv1D)             (None, 76, 15)       390         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_129 (Conv1D)             (None, 74, 15)       540         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_130 (Conv1D)             (None, 72, 15)       690         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_131 (Conv1D)             (None, 70, 15)       840         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_132 (Conv1D)             (None, 68, 15)       990         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_133 (Conv1D)             (None, 66, 15)       1140        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_134 (Conv1D)             (None, 64, 15)       1290        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_135 (Conv1D)             (None, 62, 15)       1440        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 630, 15)      0           conv1d_127[0][0]                 \n",
      "                                                                 conv1d_128[0][0]                 \n",
      "                                                                 conv1d_129[0][0]                 \n",
      "                                                                 conv1d_130[0][0]                 \n",
      "                                                                 conv1d_131[0][0]                 \n",
      "                                                                 conv1d_132[0][0]                 \n",
      "                                                                 conv1d_133[0][0]                 \n",
      "                                                                 conv1d_134[0][0]                 \n",
      "                                                                 conv1d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 9450)         0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 9450)         0           flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 500)          4725500     dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 500)          0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 1)            501         dropout_25[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 4,733,561\n",
      "Trainable params: 4,733,561\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the model parameters\n",
    "batch_size = int(len(y_scaled) * 0.01)  # no bigger than 1 % of data\n",
    "filters = 15\n",
    "# kernel_size\n",
    "strides = 1\n",
    "epochs = 10\n",
    "dropout = 0.1\n",
    "num_layers = 10\n",
    "\n",
    "# Define the tensorboard and checkpointer if desired\n",
    "tb = TensorBoard(log_dir='./logs', \n",
    "                 histogram_freq=3, \n",
    "                 batch_size=batch_size, \n",
    "                 write_graph=True, \n",
    "                 write_grads=True, \n",
    "                 write_images=True)\n",
    "checkpointer = ModelCheckpoint(monitor='val_acc', \n",
    "                               filepath=(CHECKPOINTS_DIR + '1dcnn_classifier_onehot.hdf5'), \n",
    "                               verbose=1, \n",
    "                               save_best_only=True)\n",
    "\n",
    "# Define the inputs\n",
    "inputs = Input(shape=(max_sequence_len, 5))\n",
    "layers = []\n",
    "\n",
    "# Build up the layers\n",
    "for i in range(2, num_layers + 1):\n",
    "    kernel_size = (2 * i - 1)\n",
    "#     strides = kernel_size\n",
    "    layer = Conv1D(filters, kernel_size, strides)(inputs)\n",
    "    layers.append(layer)\n",
    "\n",
    "# Combine the layers\n",
    "combined = Concatenate(axis=1)(layers)\n",
    "\n",
    "# Add some flatten, dense, and dropout layers\n",
    "out = Flatten()(combined)\n",
    "out = Dropout(dropout)(out)\n",
    "out = Dense(500, activation='sigmoid')(out)\n",
    "out = Dropout(dropout)(out)\n",
    "out = Dense(1, activation='sigmoid')(out)\n",
    "# out = Dropout(dropout)(out)\n",
    "\n",
    "# Define the model with inputs and outputs, and compile.\n",
    "model = Model(inputs=inputs, outputs=out)\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.7732 - acc: 0.6577\n",
      "Epoch 00001: val_acc improved from -inf to 0.70767, saving model to /Users/joe.abbott/Documents/dataScience/capstone/ExpressYeaself/expressyeaself/models/1d_cnn/checkpoints/1dcnn_classifier_onehot.hdf5\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.7703 - acc: 0.6584 - val_loss: 0.5642 - val_acc: 0.7077\n",
      "Epoch 2/10\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.5582 - acc: 0.7086\n",
      "Epoch 00002: val_acc improved from 0.70767 to 0.72767, saving model to /Users/joe.abbott/Documents/dataScience/capstone/ExpressYeaself/expressyeaself/models/1d_cnn/checkpoints/1dcnn_classifier_onehot.hdf5\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.5577 - acc: 0.7086 - val_loss: 0.5456 - val_acc: 0.7277\n",
      "Epoch 3/10\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.5239 - acc: 0.7390\n",
      "Epoch 00003: val_acc did not improve from 0.72767\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.5237 - acc: 0.7393 - val_loss: 0.5857 - val_acc: 0.6980\n",
      "Epoch 4/10\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.4630 - acc: 0.7791\n",
      "Epoch 00004: val_acc improved from 0.72767 to 0.73433, saving model to /Users/joe.abbott/Documents/dataScience/capstone/ExpressYeaself/expressyeaself/models/1d_cnn/checkpoints/1dcnn_classifier_onehot.hdf5\n",
      "7000/7000 [==============================] - 11s 2ms/sample - loss: 0.4627 - acc: 0.7793 - val_loss: 0.5395 - val_acc: 0.7343\n",
      "Epoch 5/10\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.3878 - acc: 0.8210\n",
      "Epoch 00005: val_acc did not improve from 0.73433\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.3877 - acc: 0.8216 - val_loss: 0.5457 - val_acc: 0.7293\n",
      "Epoch 6/10\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.3123 - acc: 0.8709\n",
      "Epoch 00006: val_acc improved from 0.73433 to 0.73667, saving model to /Users/joe.abbott/Documents/dataScience/capstone/ExpressYeaself/expressyeaself/models/1d_cnn/checkpoints/1dcnn_classifier_onehot.hdf5\n",
      "7000/7000 [==============================] - 11s 2ms/sample - loss: 0.3124 - acc: 0.8709 - val_loss: 0.5402 - val_acc: 0.7367\n",
      "Epoch 7/10\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.2371 - acc: 0.9203\n",
      "Epoch 00007: val_acc did not improve from 0.73667\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.2374 - acc: 0.9197 - val_loss: 0.6438 - val_acc: 0.7037\n",
      "Epoch 8/10\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.1722 - acc: 0.9561\n",
      "Epoch 00008: val_acc did not improve from 0.73667\n",
      "7000/7000 [==============================] - 11s 2ms/sample - loss: 0.1721 - acc: 0.9561 - val_loss: 0.6177 - val_acc: 0.7257\n",
      "Epoch 9/10\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9775\n",
      "Epoch 00009: val_acc did not improve from 0.73667\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.1210 - acc: 0.9779 - val_loss: 0.6214 - val_acc: 0.7330\n",
      "Epoch 10/10\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.0861 - acc: 0.9888\n",
      "Epoch 00010: val_acc did not improve from 0.73667\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0863 - acc: 0.9889 - val_loss: 0.6452 - val_acc: 0.7310\n",
      "acc: 73.67%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,verbose=1,\n",
    "                    validation_data=(X_test, y_test), callbacks=[checkpointer])\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "score = max(history.history['val_acc'])\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score*100))\n",
    "plt = construct.plot_results(history.history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model on native data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "native_data = '/Users/joe.abbott/Documents/dataScience/capstone/ExpressYeaself/example/native_data/native_data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "native_df = pd.read_csv(native_data, sep='\\t', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>isNative</th>\n",
       "      <th>EL.originalHQ</th>\n",
       "      <th>EL.rep1</th>\n",
       "      <th>EL.rep2</th>\n",
       "      <th>EL.combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAAAAAGCGTCCCATAACCCATTATGG...</td>\n",
       "      <td>False</td>\n",
       "      <td>5.53443621041227</td>\n",
       "      <td>6.01582188960043</td>\n",
       "      <td>3.13356537988599</td>\n",
       "      <td>5.3747928587784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAAAAGCGTAAGTTGCCCCCACGTTTT...</td>\n",
       "      <td>False</td>\n",
       "      <td>12.9093976179852</td>\n",
       "      <td>12.066980214217</td>\n",
       "      <td>8.91432298428547</td>\n",
       "      <td>11.6688079710966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAACAGTGTGGCGCTGTGTGGTTTCGA...</td>\n",
       "      <td>False</td>\n",
       "      <td>14.2016886849508</td>\n",
       "      <td>12.9450275112129</td>\n",
       "      <td>10.9724846736912</td>\n",
       "      <td>13.6822701313438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTAAAGCTCCGTTTCTTCCAGTTTT...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.68284540194134</td>\n",
       "      <td>9.03400561516769</td>\n",
       "      <td>5.76362038698236</td>\n",
       "      <td>8.75879666972858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTAAATCCTTATTTGACGATTACAC...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.21989165339868</td>\n",
       "      <td>1.94900221003461</td>\n",
       "      <td>2.35891702845157</td>\n",
       "      <td>2.04109941151436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTAACCACCGGGTTCTAGTGCCTGC...</td>\n",
       "      <td>False</td>\n",
       "      <td>12.5995298334779</td>\n",
       "      <td>11.1104002740295</td>\n",
       "      <td>7.5956124541765</td>\n",
       "      <td>10.353694893179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTAACGGGCACAGGTGCTGCCAACA...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.20953567580958</td>\n",
       "      <td>8.51005358385345</td>\n",
       "      <td>4.30295922798094</td>\n",
       "      <td>7.2738020179893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTAAGAGGCCTGGATAAACCTGTCG...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.86322256856394</td>\n",
       "      <td>9.20797746332312</td>\n",
       "      <td>6.1769332906722</td>\n",
       "      <td>9.158354037783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTAATTCTGGTTCGCCCCTGTGGGA...</td>\n",
       "      <td>False</td>\n",
       "      <td>6.95444988689203</td>\n",
       "      <td>6.67642652186563</td>\n",
       "      <td>3.93563764488858</td>\n",
       "      <td>6.41161818346868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTACAATACATGTACTAGGCCTTTT...</td>\n",
       "      <td>False</td>\n",
       "      <td>6.26850310873652</td>\n",
       "      <td>5.23444391880082</td>\n",
       "      <td>3.49240960725667</td>\n",
       "      <td>5.43623802951075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTACATTTGCAGACTGCAATTACGC...</td>\n",
       "      <td>False</td>\n",
       "      <td>15.7349508558167</td>\n",
       "      <td>14.914036823121</td>\n",
       "      <td>11.9724681577501</td>\n",
       "      <td>15.0041936147454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTACCAGCTTGTAGGGGGAGATTTT...</td>\n",
       "      <td>False</td>\n",
       "      <td>10.7150554657834</td>\n",
       "      <td>10.0513208808123</td>\n",
       "      <td>6.53273508269386</td>\n",
       "      <td>9.56808928637126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTACCGTAGCGGCATAGTCTCGGTT...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.8069102946705</td>\n",
       "      <td>8.42495640845889</td>\n",
       "      <td>5.40969649841989</td>\n",
       "      <td>8.37291746466245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAACAGTTTCTTCGCCTTATTTACTTA...</td>\n",
       "      <td>False</td>\n",
       "      <td>4.29417874685037</td>\n",
       "      <td>3.92507248536374</td>\n",
       "      <td>2.54673538911809</td>\n",
       "      <td>3.88496160853283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTACTAGTATCACGGACCTCCCATG...</td>\n",
       "      <td>False</td>\n",
       "      <td>4.15610711765149</td>\n",
       "      <td>3.66498448060884</td>\n",
       "      <td>2.75626927042054</td>\n",
       "      <td>3.95921494862387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTACTCCCGAAGAGTACGTTATGTG...</td>\n",
       "      <td>False</td>\n",
       "      <td>10.6030594052989</td>\n",
       "      <td>10.1099244177972</td>\n",
       "      <td>6.54644954066982</td>\n",
       "      <td>9.57839224217874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTACTCTTGCTCCCACACGCTCGCG...</td>\n",
       "      <td>False</td>\n",
       "      <td>14.1956279960265</td>\n",
       "      <td>12.8148998087067</td>\n",
       "      <td>10.8220547665366</td>\n",
       "      <td>13.5458581306478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTAGAGGGTAATTCGTGGTAGTTCA...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.1689920662674</td>\n",
       "      <td>8.92561115273039</td>\n",
       "      <td>4.99836433036977</td>\n",
       "      <td>7.99321570687126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTAGATGATCTTCGCAAGTTGACTT...</td>\n",
       "      <td>False</td>\n",
       "      <td>3.21885020302674</td>\n",
       "      <td>0.758181594720853</td>\n",
       "      <td>2.1527990790896</td>\n",
       "      <td>0.679304194661703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTAGATGCGCCTTTTATTTCTCGGT...</td>\n",
       "      <td>False</td>\n",
       "      <td>8.88924841126742</td>\n",
       "      <td>9.14911534484859</td>\n",
       "      <td>5.78953371740315</td>\n",
       "      <td>8.7760835927367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTAGCGGCGAAAGAGTCGTGGGTGC...</td>\n",
       "      <td>False</td>\n",
       "      <td>15.8164204302523</td>\n",
       "      <td>15.5318288024834</td>\n",
       "      <td>12.2357670836592</td>\n",
       "      <td>15.397885257133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTAGTAGTATCAAAGGTTATATATA...</td>\n",
       "      <td>False</td>\n",
       "      <td>10.1246859899687</td>\n",
       "      <td>8.12417540120469</td>\n",
       "      <td>6.25705111003187</td>\n",
       "      <td>9.16773424833029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTAGTGTGTACGCAGAACCCGGGCA...</td>\n",
       "      <td>False</td>\n",
       "      <td>13.173143007626</td>\n",
       "      <td>12.6022690343165</td>\n",
       "      <td>9.22504639512321</td>\n",
       "      <td>11.9599104253644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTAGTTCATTTGGTGTTAAGATTGG...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.69808922053093</td>\n",
       "      <td>4.37488000201483</td>\n",
       "      <td>1.89286805639618</td>\n",
       "      <td>3.46828241839735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAACATCACAATTTTGTCATGTTATTC...</td>\n",
       "      <td>False</td>\n",
       "      <td>11.2891486540897</td>\n",
       "      <td>9.80431113236992</td>\n",
       "      <td>6.97390975694343</td>\n",
       "      <td>9.98982683763433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTATAGGAGTAAAACTTGTACATGA...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.07086189746455</td>\n",
       "      <td>4.93577846693123</td>\n",
       "      <td>2.15556536993056</td>\n",
       "      <td>3.9674339847441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTATAGGCATCTCGTCTCCGGTTTT...</td>\n",
       "      <td>False</td>\n",
       "      <td>3.78273131278999</td>\n",
       "      <td>3.71685145678864</td>\n",
       "      <td>2.33259717288038</td>\n",
       "      <td>3.56718548506803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTATATTAGGGGATTTTTTAACGTA...</td>\n",
       "      <td>False</td>\n",
       "      <td>3.04701410050341</td>\n",
       "      <td>1.44347640018963</td>\n",
       "      <td>2.18424901966319</td>\n",
       "      <td>1.40865908075274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTATCCCGTCTGACGTTCAGGGTTT...</td>\n",
       "      <td>False</td>\n",
       "      <td>7.04723229823401</td>\n",
       "      <td>7.67102453898548</td>\n",
       "      <td>4.05885836368933</td>\n",
       "      <td>6.85970967895981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGTATCGGTGAGTTTATTAAGGTTTT...</td>\n",
       "      <td>False</td>\n",
       "      <td>12.8220265714925</td>\n",
       "      <td>11.457408469852</td>\n",
       "      <td>7.71017982601496</td>\n",
       "      <td>10.5449737009914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70894</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTCATTTTCTGTGGCTTTCAA...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>9.66993349772865</td>\n",
       "      <td>6.14912932425982</td>\n",
       "      <td>9.1330089604581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70895</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTCCCTTAGCTAGCCGTGTTT...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>9.08147439999844</td>\n",
       "      <td>5.74054991336588</td>\n",
       "      <td>8.73294726535487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70896</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTCCTATAAGACAAGCTCGTG...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>7.29433652102407</td>\n",
       "      <td>3.73450283502914</td>\n",
       "      <td>6.43491523763131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70897</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTCCTTTCATTTTTCAAAGCA...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>10.9462136077805</td>\n",
       "      <td>8.80770426589396</td>\n",
       "      <td>11.5675768668349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70898</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTCGATGCCGCACCGTCGCCC...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>15.9917100081014</td>\n",
       "      <td>12.5926998450018</td>\n",
       "      <td>15.7457633647097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70899</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTGAAGCGCCTAGCCCTATTT...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>14</td>\n",
       "      <td>11.0696682209261</td>\n",
       "      <td>13.89055099888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70900</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTGTTTGGAGTTCTCTCCCTC...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>4.54187186363646</td>\n",
       "      <td>2.43926379186092</td>\n",
       "      <td>4.0908495358116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70901</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTTAGCGAAAATTATCCACCC...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>10.6487848126</td>\n",
       "      <td>7.699758230304</td>\n",
       "      <td>10.5670159618751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70902</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAAAATCCGATCATACATACCCATCTC...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>1.78408472711982</td>\n",
       "      <td>1.8911203760755</td>\n",
       "      <td>1.45961825922441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70903</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTTATGCTTGCAAGCCCATTG...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>5.95348005770107</td>\n",
       "      <td>4.100537785417</td>\n",
       "      <td>6.31870332145468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70904</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTTCTTTACTGTCTATTATAG...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>14.2906328699376</td>\n",
       "      <td>11.0924568999277</td>\n",
       "      <td>13.9826721693636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70905</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTTGCTCTGCATTGTTAAAAA...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>10.7338955385829</td>\n",
       "      <td>8.46784504661397</td>\n",
       "      <td>11.2849773082677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70906</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTTGTTCTTTGCAAGAACGCG...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>10.0590280377785</td>\n",
       "      <td>8.80252396933347</td>\n",
       "      <td>11.8375732592712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70907</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTTTCTGTGTTAAAAAAATGG...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>12.4027687596396</td>\n",
       "      <td>9.36893861721521</td>\n",
       "      <td>12.1116323060088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70908</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTTTCTTTTTCATGGTAAGCG...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>6</td>\n",
       "      <td>3.32598248838371</td>\n",
       "      <td>5.5613353368516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70909</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTTTGTACAATTACTTTTTTG...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>4.38295657561088</td>\n",
       "      <td>2.66071093134941</td>\n",
       "      <td>4.23987411476837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70910</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTTTTACGATTTCTTTTTACC...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>10.2789417323347</td>\n",
       "      <td>7.16585203274437</td>\n",
       "      <td>10.1575750717361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70911</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTTTTCACTCATATGGCTATC...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>3.65457657372614</td>\n",
       "      <td>2.26149300194</td>\n",
       "      <td>3.45786782117235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70912</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTTTTCATTTTTGTTTTCGCC...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>11.4447280185584</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70913</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAAAATCCGGCGGCCTTGCTATCTCTC...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>9.77089549414526</td>\n",
       "      <td>7.21209982348145</td>\n",
       "      <td>10.2195069505473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70914</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTTTTCTTTTCAAGATTTATA...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0364624307409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70915</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTTTTGCGCAAATTTCAAGAT...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>16.8147666992135</td>\n",
       "      <td>13.6968925270452</td>\n",
       "      <td>16.511403400226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70916</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTTTTTTGGCCCGGGCGCACT...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>12.6818611193218</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70917</th>\n",
       "      <td>AACTGCATTTTTTTCACATCACTTTTTTTTTTTTTCATTTTTTAGC...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>11</td>\n",
       "      <td>11.5800531623813</td>\n",
       "      <td>14.3342787086266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70918</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGAAAAAAAAAAAAAAAAAAAAAAAG...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>14</td>\n",
       "      <td>11.399199068968</td>\n",
       "      <td>14.2200818469219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70919</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGAAAAAAAAAAAAGAGGAGACTTGA...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>7.17947935898926</td>\n",
       "      <td>4.31208020020592</td>\n",
       "      <td>6.97884023211892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70920</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGAAAAAAAAAAGGGATTGGGCGGTA...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>4.12588299967176</td>\n",
       "      <td>2.47465654644378</td>\n",
       "      <td>3.91729927439433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70921</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGAAAAAAAAAATTCTCGGCACGCAA...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>16.2012792528132</td>\n",
       "      <td>12.9098770684084</td>\n",
       "      <td>16.0122214578754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70922</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGAAAAAAAGAAATTTGGAAAATTTT...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>12.1407302296346</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70923</th>\n",
       "      <td>AACTGCATTTTTTTCACATCAGAAAAAAAGATCGATGGGACGACTC...</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "      <td>13.5146511210412</td>\n",
       "      <td>11.407227184216</td>\n",
       "      <td>14.1260168964963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70924 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     seq  isNative  \\\n",
       "0      AACTGCATTTTTTTCACATCAAAAAGCGTCCCATAACCCATTATGG...     False   \n",
       "1      AACTGCATTTTTTTCACATCAAAAGCGTAAGTTGCCCCCACGTTTT...     False   \n",
       "2      AACTGCATTTTTTTCACATCAACAGTGTGGCGCTGTGTGGTTTCGA...     False   \n",
       "3      AACTGCATTTTTTTCACATCAGTAAAGCTCCGTTTCTTCCAGTTTT...     False   \n",
       "4      AACTGCATTTTTTTCACATCAGTAAATCCTTATTTGACGATTACAC...     False   \n",
       "5      AACTGCATTTTTTTCACATCAGTAACCACCGGGTTCTAGTGCCTGC...     False   \n",
       "6      AACTGCATTTTTTTCACATCAGTAACGGGCACAGGTGCTGCCAACA...     False   \n",
       "7      AACTGCATTTTTTTCACATCAGTAAGAGGCCTGGATAAACCTGTCG...     False   \n",
       "8      AACTGCATTTTTTTCACATCAGTAATTCTGGTTCGCCCCTGTGGGA...     False   \n",
       "9      AACTGCATTTTTTTCACATCAGTACAATACATGTACTAGGCCTTTT...     False   \n",
       "10     AACTGCATTTTTTTCACATCAGTACATTTGCAGACTGCAATTACGC...     False   \n",
       "11     AACTGCATTTTTTTCACATCAGTACCAGCTTGTAGGGGGAGATTTT...     False   \n",
       "12     AACTGCATTTTTTTCACATCAGTACCGTAGCGGCATAGTCTCGGTT...     False   \n",
       "13     AACTGCATTTTTTTCACATCAACAGTTTCTTCGCCTTATTTACTTA...     False   \n",
       "14     AACTGCATTTTTTTCACATCAGTACTAGTATCACGGACCTCCCATG...     False   \n",
       "15     AACTGCATTTTTTTCACATCAGTACTCCCGAAGAGTACGTTATGTG...     False   \n",
       "16     AACTGCATTTTTTTCACATCAGTACTCTTGCTCCCACACGCTCGCG...     False   \n",
       "17     AACTGCATTTTTTTCACATCAGTAGAGGGTAATTCGTGGTAGTTCA...     False   \n",
       "18     AACTGCATTTTTTTCACATCAGTAGATGATCTTCGCAAGTTGACTT...     False   \n",
       "19     AACTGCATTTTTTTCACATCAGTAGATGCGCCTTTTATTTCTCGGT...     False   \n",
       "20     AACTGCATTTTTTTCACATCAGTAGCGGCGAAAGAGTCGTGGGTGC...     False   \n",
       "21     AACTGCATTTTTTTCACATCAGTAGTAGTATCAAAGGTTATATATA...     False   \n",
       "22     AACTGCATTTTTTTCACATCAGTAGTGTGTACGCAGAACCCGGGCA...     False   \n",
       "23     AACTGCATTTTTTTCACATCAGTAGTTCATTTGGTGTTAAGATTGG...     False   \n",
       "24     AACTGCATTTTTTTCACATCAACATCACAATTTTGTCATGTTATTC...     False   \n",
       "25     AACTGCATTTTTTTCACATCAGTATAGGAGTAAAACTTGTACATGA...     False   \n",
       "26     AACTGCATTTTTTTCACATCAGTATAGGCATCTCGTCTCCGGTTTT...     False   \n",
       "27     AACTGCATTTTTTTCACATCAGTATATTAGGGGATTTTTTAACGTA...     False   \n",
       "28     AACTGCATTTTTTTCACATCAGTATCCCGTCTGACGTTCAGGGTTT...     False   \n",
       "29     AACTGCATTTTTTTCACATCAGTATCGGTGAGTTTATTAAGGTTTT...     False   \n",
       "...                                                  ...       ...   \n",
       "70894  AACTGCATTTTTTTCACATCACTTTTTCATTTTCTGTGGCTTTCAA...      True   \n",
       "70895  AACTGCATTTTTTTCACATCACTTTTTCCCTTAGCTAGCCGTGTTT...      True   \n",
       "70896  AACTGCATTTTTTTCACATCACTTTTTCCTATAAGACAAGCTCGTG...      True   \n",
       "70897  AACTGCATTTTTTTCACATCACTTTTTCCTTTCATTTTTCAAAGCA...      True   \n",
       "70898  AACTGCATTTTTTTCACATCACTTTTTCGATGCCGCACCGTCGCCC...      True   \n",
       "70899  AACTGCATTTTTTTCACATCACTTTTTGAAGCGCCTAGCCCTATTT...      True   \n",
       "70900  AACTGCATTTTTTTCACATCACTTTTTGTTTGGAGTTCTCTCCCTC...      True   \n",
       "70901  AACTGCATTTTTTTCACATCACTTTTTTAGCGAAAATTATCCACCC...      True   \n",
       "70902  AACTGCATTTTTTTCACATCAAAATCCGATCATACATACCCATCTC...      True   \n",
       "70903  AACTGCATTTTTTTCACATCACTTTTTTATGCTTGCAAGCCCATTG...      True   \n",
       "70904  AACTGCATTTTTTTCACATCACTTTTTTCTTTACTGTCTATTATAG...      True   \n",
       "70905  AACTGCATTTTTTTCACATCACTTTTTTGCTCTGCATTGTTAAAAA...      True   \n",
       "70906  AACTGCATTTTTTTCACATCACTTTTTTGTTCTTTGCAAGAACGCG...      True   \n",
       "70907  AACTGCATTTTTTTCACATCACTTTTTTTCTGTGTTAAAAAAATGG...      True   \n",
       "70908  AACTGCATTTTTTTCACATCACTTTTTTTCTTTTTCATGGTAAGCG...      True   \n",
       "70909  AACTGCATTTTTTTCACATCACTTTTTTTGTACAATTACTTTTTTG...      True   \n",
       "70910  AACTGCATTTTTTTCACATCACTTTTTTTTACGATTTCTTTTTACC...      True   \n",
       "70911  AACTGCATTTTTTTCACATCACTTTTTTTTCACTCATATGGCTATC...      True   \n",
       "70912  AACTGCATTTTTTTCACATCACTTTTTTTTCATTTTTGTTTTCGCC...      True   \n",
       "70913  AACTGCATTTTTTTCACATCAAAATCCGGCGGCCTTGCTATCTCTC...      True   \n",
       "70914  AACTGCATTTTTTTCACATCACTTTTTTTTCTTTTCAAGATTTATA...      True   \n",
       "70915  AACTGCATTTTTTTCACATCACTTTTTTTTGCGCAAATTTCAAGAT...      True   \n",
       "70916  AACTGCATTTTTTTCACATCACTTTTTTTTTTGGCCCGGGCGCACT...      True   \n",
       "70917  AACTGCATTTTTTTCACATCACTTTTTTTTTTTTTCATTTTTTAGC...      True   \n",
       "70918  AACTGCATTTTTTTCACATCAGAAAAAAAAAAAAAAAAAAAAAAAG...      True   \n",
       "70919  AACTGCATTTTTTTCACATCAGAAAAAAAAAAAAGAGGAGACTTGA...      True   \n",
       "70920  AACTGCATTTTTTTCACATCAGAAAAAAAAAAGGGATTGGGCGGTA...      True   \n",
       "70921  AACTGCATTTTTTTCACATCAGAAAAAAAAAATTCTCGGCACGCAA...      True   \n",
       "70922  AACTGCATTTTTTTCACATCAGAAAAAAAGAAATTTGGAAAATTTT...      True   \n",
       "70923  AACTGCATTTTTTTCACATCAGAAAAAAAGATCGATGGGACGACTC...      True   \n",
       "\n",
       "          EL.originalHQ            EL.rep1           EL.rep2  \\\n",
       "0      5.53443621041227   6.01582188960043  3.13356537988599   \n",
       "1      12.9093976179852    12.066980214217  8.91432298428547   \n",
       "2      14.2016886849508   12.9450275112129  10.9724846736912   \n",
       "3      9.68284540194134   9.03400561516769  5.76362038698236   \n",
       "4      2.21989165339868   1.94900221003461  2.35891702845157   \n",
       "5      12.5995298334779   11.1104002740295   7.5956124541765   \n",
       "6      9.20953567580958   8.51005358385345  4.30295922798094   \n",
       "7      9.86322256856394   9.20797746332312   6.1769332906722   \n",
       "8      6.95444988689203   6.67642652186563  3.93563764488858   \n",
       "9      6.26850310873652   5.23444391880082  3.49240960725667   \n",
       "10     15.7349508558167    14.914036823121  11.9724681577501   \n",
       "11     10.7150554657834   10.0513208808123  6.53273508269386   \n",
       "12      9.8069102946705   8.42495640845889  5.40969649841989   \n",
       "13     4.29417874685037   3.92507248536374  2.54673538911809   \n",
       "14     4.15610711765149   3.66498448060884  2.75626927042054   \n",
       "15     10.6030594052989   10.1099244177972  6.54644954066982   \n",
       "16     14.1956279960265   12.8148998087067  10.8220547665366   \n",
       "17      9.1689920662674   8.92561115273039  4.99836433036977   \n",
       "18     3.21885020302674  0.758181594720853   2.1527990790896   \n",
       "19     8.88924841126742   9.14911534484859  5.78953371740315   \n",
       "20     15.8164204302523   15.5318288024834  12.2357670836592   \n",
       "21     10.1246859899687   8.12417540120469  6.25705111003187   \n",
       "22      13.173143007626   12.6022690343165  9.22504639512321   \n",
       "23     2.69808922053093   4.37488000201483  1.89286805639618   \n",
       "24     11.2891486540897   9.80431113236992  6.97390975694343   \n",
       "25     2.07086189746455   4.93577846693123  2.15556536993056   \n",
       "26     3.78273131278999   3.71685145678864  2.33259717288038   \n",
       "27     3.04701410050341   1.44347640018963  2.18424901966319   \n",
       "28     7.04723229823401   7.67102453898548  4.05885836368933   \n",
       "29     12.8220265714925    11.457408469852  7.71017982601496   \n",
       "...                 ...                ...               ...   \n",
       "70894                NA   9.66993349772865  6.14912932425982   \n",
       "70895                NA   9.08147439999844  5.74054991336588   \n",
       "70896                NA   7.29433652102407  3.73450283502914   \n",
       "70897                NA   10.9462136077805  8.80770426589396   \n",
       "70898                NA   15.9917100081014  12.5926998450018   \n",
       "70899                NA                 14  11.0696682209261   \n",
       "70900                NA   4.54187186363646  2.43926379186092   \n",
       "70901                NA      10.6487848126    7.699758230304   \n",
       "70902                NA   1.78408472711982   1.8911203760755   \n",
       "70903                NA   5.95348005770107    4.100537785417   \n",
       "70904                NA   14.2906328699376  11.0924568999277   \n",
       "70905                NA   10.7338955385829  8.46784504661397   \n",
       "70906                NA   10.0590280377785  8.80252396933347   \n",
       "70907                NA   12.4027687596396  9.36893861721521   \n",
       "70908                NA                  6  3.32598248838371   \n",
       "70909                NA   4.38295657561088  2.66071093134941   \n",
       "70910                NA   10.2789417323347  7.16585203274437   \n",
       "70911                NA   3.65457657372614     2.26149300194   \n",
       "70912                NA                 NA  11.4447280185584   \n",
       "70913                NA   9.77089549414526  7.21209982348145   \n",
       "70914                NA                 10                 7   \n",
       "70915                NA   16.8147666992135  13.6968925270452   \n",
       "70916                NA                 NA  12.6818611193218   \n",
       "70917                NA                 11  11.5800531623813   \n",
       "70918                NA                 14   11.399199068968   \n",
       "70919                NA   7.17947935898926  4.31208020020592   \n",
       "70920                NA   4.12588299967176  2.47465654644378   \n",
       "70921                NA   16.2012792528132  12.9098770684084   \n",
       "70922                NA                 NA  12.1407302296346   \n",
       "70923                NA   13.5146511210412   11.407227184216   \n",
       "\n",
       "             EL.combined  \n",
       "0        5.3747928587784  \n",
       "1       11.6688079710966  \n",
       "2       13.6822701313438  \n",
       "3       8.75879666972858  \n",
       "4       2.04109941151436  \n",
       "5        10.353694893179  \n",
       "6        7.2738020179893  \n",
       "7         9.158354037783  \n",
       "8       6.41161818346868  \n",
       "9       5.43623802951075  \n",
       "10      15.0041936147454  \n",
       "11      9.56808928637126  \n",
       "12      8.37291746466245  \n",
       "13      3.88496160853283  \n",
       "14      3.95921494862387  \n",
       "15      9.57839224217874  \n",
       "16      13.5458581306478  \n",
       "17      7.99321570687126  \n",
       "18     0.679304194661703  \n",
       "19       8.7760835927367  \n",
       "20       15.397885257133  \n",
       "21      9.16773424833029  \n",
       "22      11.9599104253644  \n",
       "23      3.46828241839735  \n",
       "24      9.98982683763433  \n",
       "25       3.9674339847441  \n",
       "26      3.56718548506803  \n",
       "27      1.40865908075274  \n",
       "28      6.85970967895981  \n",
       "29      10.5449737009914  \n",
       "...                  ...  \n",
       "70894    9.1330089604581  \n",
       "70895   8.73294726535487  \n",
       "70896   6.43491523763131  \n",
       "70897   11.5675768668349  \n",
       "70898   15.7457633647097  \n",
       "70899     13.89055099888  \n",
       "70900    4.0908495358116  \n",
       "70901   10.5670159618751  \n",
       "70902   1.45961825922441  \n",
       "70903   6.31870332145468  \n",
       "70904   13.9826721693636  \n",
       "70905   11.2849773082677  \n",
       "70906   11.8375732592712  \n",
       "70907   12.1116323060088  \n",
       "70908    5.5613353368516  \n",
       "70909   4.23987411476837  \n",
       "70910   10.1575750717361  \n",
       "70911   3.45786782117235  \n",
       "70912                 NA  \n",
       "70913   10.2195069505473  \n",
       "70914   10.0364624307409  \n",
       "70915    16.511403400226  \n",
       "70916                 NA  \n",
       "70917   14.3342787086266  \n",
       "70918   14.2200818469219  \n",
       "70919   6.97884023211892  \n",
       "70920   3.91729927439433  \n",
       "70921   16.0122214578754  \n",
       "70922                 NA  \n",
       "70923   14.1260168964963  \n",
       "\n",
       "[70924 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "native_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Series' objects are mutable, thus they cannot be hashed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-1d04db2f8b31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnative_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnative_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'isNative'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/yeast/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, axis)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mnew_self\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/yeast/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_axis_number\u001b[0;34m(cls, axis)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_ALIASES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_NAMES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/yeast/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1814\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1815\u001b[0m         raise TypeError('{0!r} objects are mutable, thus they cannot be'\n\u001b[0;32m-> 1816\u001b[0;31m                         ' hashed'.format(self.__class__.__name__))\n\u001b[0m\u001b[1;32m   1817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1818\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Series' objects are mutable, thus they cannot be hashed"
     ]
    }
   ],
   "source": [
    "native_df.iloc(native_df['isNative'] == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yeast",
   "language": "python",
   "name": "yeast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
