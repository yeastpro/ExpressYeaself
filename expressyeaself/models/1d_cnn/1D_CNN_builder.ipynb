{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the 1D CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import context\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import (Add, Concatenate, Input, Dense, \n",
    "                                            Dropout, Embedding, Conv1D, \n",
    "                                            MaxPooling1D, GlobalAveragePooling1D, \n",
    "                                            Flatten)\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "ROOT_DIR = os.getcwd()[:os.getcwd().rfind('Express')] + 'ExpressYeaself/'\n",
    "SAVE_DIR = ROOT_DIR + 'expressyeaself/models/1d_cnn/saved_models/'\n",
    "\n",
    "build = context.build_promoter\n",
    "construct = context.construct_neural_net\n",
    "encode = context.encode_sequences\n",
    "organize = context.organize_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define filename of input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_filename = ('10000_from_20190612130111781831_percentiles_els_binarized_homogeneous_deflanked_'\n",
    "                   'sequences_with_exp_levels.txt.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the absolute path of this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = ROOT_DIR + 'example/processed_data/' + sample_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_padded, y_scaled, abs_max_el = encode.encode_sequences_with_method(sample_path, \n",
    "                                                                     method='One-Hot', \n",
    "                                                                     scale_els=True, \n",
    "                                                                     model_type='1DCNN', \n",
    "                                                                     binarized_els=True)\n",
    "num_seqs, max_sequence_len = organize.get_num_and_len_of_seqs_from_file(sample_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape expression level array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scaled = y_scaled.reshape((len(y_scaled), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_scaled, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 78, 15)            240       \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 76, 15)            690       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 74, 15)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 72, 15)            690       \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 70, 15)            690       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 2,326\n",
      "Trainable params: 2,326\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the model parameters\n",
    "batch_size = int(len(y_scaled) * 0.01)  # no bigger than 1 % of data\n",
    "filters = 15\n",
    "kernel_size = 3\n",
    "strides = 1\n",
    "epochs = 20\n",
    "dropout = 0.5\n",
    "\n",
    "# Define the checkpointer to allow saving of models\n",
    "model_type = '1d_cnn_sequential_onehot'\n",
    "save_path = SAVE_DIR + model_type + '.hdf5'\n",
    "checkpointer = ModelCheckpoint(monitor='val_acc', \n",
    "                               filepath=save_path, \n",
    "                               verbose=1, \n",
    "                               save_best_only=True)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Build up the layers\n",
    "model.add(Conv1D(filters, kernel_size, activation='relu', \n",
    "                 input_shape=(max_sequence_len, 5), \n",
    "                 kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "model.add(MaxPooling1D(3, strides))\n",
    "# keras.layers.Flatten(data_format=None)\n",
    "# model.add(GlobalAveragePooling1D())\n",
    "model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "\n",
    "# Add some dense and dropout layers\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 80, 5)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 80, 15)       90          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 78, 15)       240         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 76, 15)       390         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 74, 15)       540         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 72, 15)       690         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 70, 15)       840         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 68, 15)       990         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 66, 15)       1140        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 64, 15)       1290        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 62, 15)       1440        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 710, 15)      0           conv1d[0][0]                     \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 10650)        0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 500)          5325500     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 500)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            501         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,333,651\n",
      "Trainable params: 5,333,651\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the model parameters\n",
    "batch_size = int(len(y_scaled) * 0.01)  # no bigger than 1 % of data\n",
    "filters = 15\n",
    "# kernel_size\n",
    "strides = 1\n",
    "epochs = 20\n",
    "dropout = 0.1\n",
    "num_layers = 10\n",
    "\n",
    "# Define the checkpointer to allow saving of models\n",
    "model_type = '1d_cnn_parallel_onehot'\n",
    "save_path = SAVE_DIR + model_type + '.hdf5'\n",
    "checkpointer = ModelCheckpoint(monitor='val_acc', \n",
    "                               filepath=save_path, \n",
    "                               verbose=1, \n",
    "                               save_best_only=True)\n",
    "\n",
    "# Define the inputs\n",
    "inputs = Input(shape=(max_sequence_len, 5))\n",
    "layers = []\n",
    "\n",
    "# Build up the layers\n",
    "for i in range(1, num_layers + 1):\n",
    "    layer = Conv1D(filters, (2 * i - 1), strides)(inputs)\n",
    "    layers.append(layer)\n",
    "\n",
    "# Combine the layers\n",
    "combined = Concatenate(axis=1)(layers)\n",
    "\n",
    "# Add some flatten, dense, and dropout layers\n",
    "out = Flatten()(combined)\n",
    "# out = Dropout(dropout)(out)\n",
    "out = Dense(500, activation='sigmoid')(out)\n",
    "out = Dropout(dropout)(out)\n",
    "out = Dense(1, activation='sigmoid')(out)\n",
    "out = Dropout(dropout)(out)\n",
    "\n",
    "# Define the model with inputs and outputs, and compile.\n",
    "model = Model(inputs=inputs, outputs=out)\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Has same parallel layer architecture as the _Parallel Model_.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0614 18:09:57.824165 4550550976 deprecation.py:323] From /Users/joe.abbott/miniconda3/envs/yeast/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:182: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 80, 5)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 78, 15)       240         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 76, 15)       390         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 74, 15)       540         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 72, 15)       690         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 70, 15)       840         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 68, 15)       990         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 66, 15)       1140        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 64, 15)       1290        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 62, 15)       1440        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 630, 15)      0           conv1d_14[0][0]                  \n",
      "                                                                 conv1d_15[0][0]                  \n",
      "                                                                 conv1d_16[0][0]                  \n",
      "                                                                 conv1d_17[0][0]                  \n",
      "                                                                 conv1d_18[0][0]                  \n",
      "                                                                 conv1d_19[0][0]                  \n",
      "                                                                 conv1d_20[0][0]                  \n",
      "                                                                 conv1d_21[0][0]                  \n",
      "                                                                 conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 9450)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 9450)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 500)          4725500     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 500)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            501         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,733,561\n",
      "Trainable params: 4,733,561\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the model parameters\n",
    "batch_size = int(len(y_scaled) * 0.01)  # no bigger than 1 % of data\n",
    "filters = 15\n",
    "# kernel_size\n",
    "strides = 1\n",
    "epochs = 20\n",
    "dropout = 0.1\n",
    "num_layers = 10\n",
    "\n",
    "# Define the checkpointer to allow saving of models\n",
    "model_type = '1d_cnn_classifier_onehot'\n",
    "save_path = SAVE_DIR + model_type + '.hdf5'\n",
    "checkpointer = ModelCheckpoint(monitor='val_acc', \n",
    "                               filepath=save_path, \n",
    "                               verbose=1, \n",
    "                               save_best_only=True)\n",
    "\n",
    "# Define the inputs\n",
    "inputs = Input(shape=(max_sequence_len, 5))\n",
    "layers = []\n",
    "\n",
    "# Build up the layers\n",
    "for i in range(2, num_layers + 1):\n",
    "    kernel_size = (2 * i - 1)\n",
    "#     strides = kernel_size\n",
    "    layer = Conv1D(filters, kernel_size, strides)(inputs)\n",
    "    layers.append(layer)\n",
    "\n",
    "# Combine the layers\n",
    "combined = Concatenate(axis=1)(layers)\n",
    "\n",
    "# Add some flatten, dense, and dropout layers\n",
    "out = Flatten()(combined)\n",
    "out = Dropout(dropout)(out)\n",
    "out = Dense(500, activation='sigmoid')(out)\n",
    "out = Dropout(dropout)(out)\n",
    "out = Dense(1, activation='sigmoid')(out)\n",
    "# out = Dropout(dropout)(out)\n",
    "\n",
    "# Define the model with inputs and outputs, and compile.\n",
    "model = Model(inputs=inputs, outputs=out)\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.2766 - acc: 0.6467\n",
      "Epoch 00001: val_acc improved from -inf to 0.72700, saving model to /Users/joe.abbott/Documents/dataScience/capstone/ExpressYeaself/expressyeaself/models/1d_cnn/saved_models/1d_cnn_parallel_onehot.hdf5\n",
      "7000/7000 [==============================] - 7s 1ms/sample - loss: 0.2759 - acc: 0.6474 - val_loss: 0.1850 - val_acc: 0.7270\n",
      "Epoch 2/20\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.2148 - acc: 0.7043\n",
      "Epoch 00002: val_acc improved from 0.72700 to 0.73167, saving model to /Users/joe.abbott/Documents/dataScience/capstone/ExpressYeaself/expressyeaself/models/1d_cnn/saved_models/1d_cnn_parallel_onehot.hdf5\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.2149 - acc: 0.7043 - val_loss: 0.1816 - val_acc: 0.7317\n",
      "Epoch 3/20\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.2050 - acc: 0.7239\n",
      "Epoch 00003: val_acc improved from 0.73167 to 0.73967, saving model to /Users/joe.abbott/Documents/dataScience/capstone/ExpressYeaself/expressyeaself/models/1d_cnn/saved_models/1d_cnn_parallel_onehot.hdf5\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.2050 - acc: 0.7239 - val_loss: 0.1776 - val_acc: 0.7397\n",
      "Epoch 4/20\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.2018 - acc: 0.7296\n",
      "Epoch 00004: val_acc improved from 0.73967 to 0.74600, saving model to /Users/joe.abbott/Documents/dataScience/capstone/ExpressYeaself/expressyeaself/models/1d_cnn/saved_models/1d_cnn_parallel_onehot.hdf5\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.2020 - acc: 0.7299 - val_loss: 0.1779 - val_acc: 0.7460\n",
      "Epoch 5/20\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.1854 - acc: 0.7593\n",
      "Epoch 00005: val_acc did not improve from 0.74600\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.1852 - acc: 0.7591 - val_loss: 0.1757 - val_acc: 0.7443\n",
      "Epoch 6/20\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.1630 - acc: 0.8042\n",
      "Epoch 00006: val_acc did not improve from 0.74600\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.1629 - acc: 0.8041 - val_loss: 0.1777 - val_acc: 0.7320\n",
      "Epoch 7/20\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.8474\n",
      "Epoch 00007: val_acc did not improve from 0.74600\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.1398 - acc: 0.8471 - val_loss: 0.1806 - val_acc: 0.7337\n",
      "Epoch 8/20\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.8914\n",
      "Epoch 00008: val_acc did not improve from 0.74600\n",
      "7000/7000 [==============================] - 10s 1ms/sample - loss: 0.1100 - acc: 0.8921 - val_loss: 0.1892 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9194\n",
      "Epoch 00009: val_acc did not improve from 0.74600\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0915 - acc: 0.9194 - val_loss: 0.1892 - val_acc: 0.7187\n",
      "Epoch 10/20\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9310\n",
      "Epoch 00010: val_acc did not improve from 0.74600\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0795 - acc: 0.9313 - val_loss: 0.1870 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9364\n",
      "Epoch 00011: val_acc did not improve from 0.74600\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0724 - acc: 0.9370 - val_loss: 0.1870 - val_acc: 0.7193\n",
      "Epoch 12/20\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9443\n",
      "Epoch 00012: val_acc did not improve from 0.74600\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0616 - acc: 0.9447 - val_loss: 0.1912 - val_acc: 0.7150\n",
      "Epoch 13/20\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9462\n",
      "Epoch 00013: val_acc did not improve from 0.74600\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0588 - acc: 0.9463 - val_loss: 0.1969 - val_acc: 0.7187\n",
      "Epoch 14/20\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9509\n",
      "Epoch 00014: val_acc did not improve from 0.74600\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0530 - acc: 0.9510 - val_loss: 0.1912 - val_acc: 0.7173\n",
      "Epoch 15/20\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9457\n",
      "Epoch 00015: val_acc did not improve from 0.74600\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0581 - acc: 0.9454 - val_loss: 0.1946 - val_acc: 0.7293\n",
      "Epoch 16/20\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9475\n",
      "Epoch 00016: val_acc did not improve from 0.74600\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0556 - acc: 0.9474 - val_loss: 0.1942 - val_acc: 0.7203\n",
      "Epoch 17/20\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9422\n",
      "Epoch 00017: val_acc did not improve from 0.74600\n",
      "7000/7000 [==============================] - 10s 1ms/sample - loss: 0.0608 - acc: 0.9420 - val_loss: 0.1993 - val_acc: 0.7160\n",
      "Epoch 18/20\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9457\n",
      "Epoch 00018: val_acc did not improve from 0.74600\n",
      "7000/7000 [==============================] - 10s 1ms/sample - loss: 0.0568 - acc: 0.9456 - val_loss: 0.1953 - val_acc: 0.7180\n",
      "Epoch 19/20\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.0528 - acc: 0.9496\n",
      "Epoch 00019: val_acc did not improve from 0.74600\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0532 - acc: 0.9491 - val_loss: 0.1969 - val_acc: 0.7160\n",
      "Epoch 20/20\n",
      "6900/7000 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9446\n",
      "Epoch 00020: val_acc did not improve from 0.74600\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0578 - acc: 0.9444 - val_loss: 0.1981 - val_acc: 0.7123\n",
      "acc: 74.60%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,verbose=1,\n",
    "                    validation_data=(X_test, y_test), callbacks=[checkpointer])\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "score = max(history.history['val_acc'])\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score*100))\n",
    "plt = construct.plot_results(history.history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking predictions on a small sample of native data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seqs = ROOT_DIR + 'expressyeaself/models/1d_cnn/native_sample.txt'\n",
    "model_to_use = '1d_cnn_sequential'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0614 18:09:09.709701 4550550976 deprecation.py:506] From /Users/joe.abbott/miniconda3/envs/yeast/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0614 18:09:09.711513 4550550976 deprecation.py:506] From /Users/joe.abbott/miniconda3/envs/yeast/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "/Users/joe.abbott/Documents/dataScience/capstone/ExpressYeaself/expressyeaself/construct_neural_net.py:186: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  results_df['el_prediction'][i] = pred\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seq</th>\n",
       "      <th>el_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>AGTGCGGGGGTCTAGGTCTCAGGTTAACTAGTGGATGCGGATGCTG...</td>\n",
       "      <td>0.975779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>AGTACTCTTGCTCCCACACGCTCGCGCCTGGTACGTCTAAGGACGG...</td>\n",
       "      <td>0.940327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95</td>\n",
       "      <td>AGTGGAATTGTACGGGGCACATCTTAGGCAGGGGTGGATGCGGCTT...</td>\n",
       "      <td>0.856257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>AGTATGTCGTCGCGTGTTGTTTCTAATCTTCGTGGCCTGTGGTGCA...</td>\n",
       "      <td>0.834777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>AGTAGTGTGTACGCAGAACCCGGGCATGATCCTGCGCGACAACTTT...</td>\n",
       "      <td>0.779282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>AGTCACTGGCCATTAGCGACGAAGTCTGTTGTCGTGGGTGCGAAGC...</td>\n",
       "      <td>0.778203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>AGTAGCGGCGAAAGAGTCGTGGGTGCGCAGGTCTGCTCGCTTGGGG...</td>\n",
       "      <td>0.776115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>96</td>\n",
       "      <td>AGTGGCATGTTGTGCTGTGTCGGGTCAGACAGGCATGGTGGTCAGG...</td>\n",
       "      <td>0.766534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>AAAAGCGTAAGTTGCCCCCACGTTTTTCAGCGCTGCTGCGGAAGCG...</td>\n",
       "      <td>0.746711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>58</td>\n",
       "      <td>AGTCGCTCGGAACGTTACAGTTCCGGGGTACAAGACGGGTTATTCT...</td>\n",
       "      <td>0.729927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>AGTACTCCCGAAGAGTACGTTATGTGTGGACTTGACCGCCTGGGGG...</td>\n",
       "      <td>0.727682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>37</td>\n",
       "      <td>AGTATTAACGTGGCCTACTGTTCTTACTGTCCAGCGTCGTGTTTCA...</td>\n",
       "      <td>0.709952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>74</td>\n",
       "      <td>AGTCTTGACCGCGGAAAACTAGGTCTTGGTCCTGTCTCAGGAGGAT...</td>\n",
       "      <td>0.702116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>84</td>\n",
       "      <td>AGTGCAGCAGGCCAGGGTTGGTTTAGGGCAGGCTATACGGTGCCGA...</td>\n",
       "      <td>0.697783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>AGTAAGAGGCCTGGATAAACCTGTCGGATAAGATTCGTCTACAAAT...</td>\n",
       "      <td>0.692216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>35</td>\n",
       "      <td>AACATGTCTCACCGTAGGCGTAAGCAACGCCAGCACACACAGTTGC...</td>\n",
       "      <td>0.668215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31</td>\n",
       "      <td>AGTATGATGTTGAAAACACGAAGATTGGTCTTTTCGGGGGAAAGCC...</td>\n",
       "      <td>0.667329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>93</td>\n",
       "      <td>AGTGCTTAGGAGCGGGGTTTAGGGGCGCTGCGTCTGGTATCCTATG...</td>\n",
       "      <td>0.661053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>72</td>\n",
       "      <td>AGTCTCGCGTTTGTTTACGGGTGGTTCGCTTGTAATCGATGCGCTT...</td>\n",
       "      <td>0.659408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>67</td>\n",
       "      <td>AGTCTAGTTTCATGGCTTGCGGGCTAAGTGTGGAATTGTTGTAGTT...</td>\n",
       "      <td>0.657779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>83</td>\n",
       "      <td>AGTGATTTCTAGGTCACCTATCGTATCTGCTTCAATGATGTTATGA...</td>\n",
       "      <td>0.634959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24</td>\n",
       "      <td>AACATCACAATTTTGTCATGTTATTCGCAGGAATCATTCCGCGCAT...</td>\n",
       "      <td>0.633381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>36</td>\n",
       "      <td>AGTATGTGGGTGGGGAGGTCAGTGTGAGGGGAGCGTGGGGATCTAT...</td>\n",
       "      <td>0.628763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8</td>\n",
       "      <td>AGTAATTCTGGTTCGCCCCTGTGGGATGGTATCAAAAGAAGGATGG...</td>\n",
       "      <td>0.617448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>66</td>\n",
       "      <td>AGTCTAGGCTGGGGCGCCAGAAGGGCATGGTTTTGACGATGGGGTA...</td>\n",
       "      <td>0.614584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>77</td>\n",
       "      <td>AGTGACCAAGGCTCACGCCGGTCTGGTCGGATACAGGGTAGACGTT...</td>\n",
       "      <td>0.612849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>AACAGTGTGGCGCTGTGTGGTTTCGAGGGGACGGCACGGGGATGAA...</td>\n",
       "      <td>0.611789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>88</td>\n",
       "      <td>AGTGCGTCTAGTCGTTGTCGCGTGGTGGACGTGGGACCTCGGTAGG...</td>\n",
       "      <td>0.594199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>57</td>\n",
       "      <td>AACATTGTCTGATGATTCGAGTATACCAAGTTCGTGAAAGGTGAGG...</td>\n",
       "      <td>0.587134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>48</td>\n",
       "      <td>AGTCCACTAAGGAATTCCGGCTTCCAACGGATAGTTCGGCGTACTA...</td>\n",
       "      <td>0.584215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>75</td>\n",
       "      <td>AGTCTTTGGCGATCGTCGCCCCTATAGGTTGCTAAGAGGTACTGGA...</td>\n",
       "      <td>0.351753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>97</td>\n",
       "      <td>AGTGTACCGGCTGTATTTAAGGACCTTGTGAGCAAGTTCAAGGGGT...</td>\n",
       "      <td>0.322393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>30</td>\n",
       "      <td>AGTATCTGAAAGGTACGTGTTCTAGTTTAATTGGACATGCCCGAGT...</td>\n",
       "      <td>0.318473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>71</td>\n",
       "      <td>AGTCTCATTCCTATTTCTACGAGAGATGTTTATATCCGTGGATCGT...</td>\n",
       "      <td>0.314584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>6</td>\n",
       "      <td>AGTAACGGGCACAGGTGCTGCCAACATTTCTGTTTATACAAGCAGC...</td>\n",
       "      <td>0.305360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>45</td>\n",
       "      <td>AGTCATCTAGACTTTAATGCTTCGTTTGGCGGTTTAGCCCAATGAA...</td>\n",
       "      <td>0.294646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>89</td>\n",
       "      <td>AGTGCTAAAGCTGTAAATGCCTGGAATCGCAGGAAATGGTAGTATC...</td>\n",
       "      <td>0.292869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>62</td>\n",
       "      <td>AGTCGTGTGATGTTGGTTGGATGGGGCGATGAAGTGGAAGGTCAGA...</td>\n",
       "      <td>0.292501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>52</td>\n",
       "      <td>AGTCCGTTGATGTGTGTGCCTGTAATTTCGTTCACCATAGGACACA...</td>\n",
       "      <td>0.286384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>61</td>\n",
       "      <td>AGTCGTGGTTCACCCTGACCTGCAAAGAGTATGGATCGGGAGTAAC...</td>\n",
       "      <td>0.272403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>43</td>\n",
       "      <td>AGTCAGGAAAGACGCAGTCAGTTTGATTCCGTATGATACAATTGTG...</td>\n",
       "      <td>0.260749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>17</td>\n",
       "      <td>AGTAGAGGGTAATTCGTGGTAGTTCAACCTTGGTAGGGAGCCGTCA...</td>\n",
       "      <td>0.254779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>79</td>\n",
       "      <td>AACCAATTTGGTTGTAATCGTTGGCTTTCCATATGGTGTTCACCAT...</td>\n",
       "      <td>0.254244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>55</td>\n",
       "      <td>AGTCGATTTAGCCCTTCATCGTTCCAAGTGCGATTATGAGACGAAA...</td>\n",
       "      <td>0.253605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>23</td>\n",
       "      <td>AGTAGTTCATTTGGTGTTAAGATTGGCATATAGCTCAGTTCATTGG...</td>\n",
       "      <td>0.239642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>AGTGCCCTGTCTTGCTTGTTGGGCGAATATAATCTTTTTCGTGCAC...</td>\n",
       "      <td>0.235702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>9</td>\n",
       "      <td>AGTACAATACATGTACTAGGCCTTTTAGTTTAGTCAGTGACATATC...</td>\n",
       "      <td>0.231761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>99</td>\n",
       "      <td>AGTGTAGAAGAGTCTACCGGGTACCTCGTTAATCAAACAGGCCACT...</td>\n",
       "      <td>0.229215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>44</td>\n",
       "      <td>AGTCAGTGTTAGTGTTAGACGCTGAGCGGTTCTACAGGCTCGGTAA...</td>\n",
       "      <td>0.218834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>51</td>\n",
       "      <td>AGTCCGAGCTAGACTACGCTTTAAATTTGGATCAAGTTCTCGAAGT...</td>\n",
       "      <td>0.201864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>29</td>\n",
       "      <td>AGTATCGGTGAGTTTATTAAGGTTTTACTCTAATGTGGGGGACTAA...</td>\n",
       "      <td>0.196002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>47</td>\n",
       "      <td>AGTCCAAAGAGGTTCCCAGTACTGGAAAAGGGTTAGATGGGTTGAG...</td>\n",
       "      <td>0.190039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>27</td>\n",
       "      <td>AGTATATTAGGGGATTTTTTAACGTACTTTGATCAAGTGACTCATC...</td>\n",
       "      <td>0.189980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>4</td>\n",
       "      <td>AGTAAATCCTTATTTGACGATTACACACTTAACTAGCACCCCTCTT...</td>\n",
       "      <td>0.189049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>18</td>\n",
       "      <td>AGTAGATGATCTTCGCAAGTTGACTTATTCGCTGTTTTGGATTTGA...</td>\n",
       "      <td>0.188553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>85</td>\n",
       "      <td>AGTGCATCATAGGCCATCTAAAGGTGAAACTGATTTTTCGTATGTA...</td>\n",
       "      <td>0.184068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>65</td>\n",
       "      <td>AGTCTAGATTATTGTCACTTCTGAGGTGGTATAGCGATCCTAGCTG...</td>\n",
       "      <td>0.181779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>25</td>\n",
       "      <td>AGTATAGGAGTAAAACTTGTACATGAGTTTACTCATTAATTGTCTT...</td>\n",
       "      <td>0.174911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>21</td>\n",
       "      <td>AGTAGTAGTATCAAAGGTTATATATACACGTAGTTTGTATAACAGA...</td>\n",
       "      <td>0.166833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>81</td>\n",
       "      <td>AGTGACTAAGAGTGTTCTGGTAGGTTTATTGTAACCCTAAGGATTT...</td>\n",
       "      <td>0.138155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                                seq  el_prediction\n",
       "0      87  AGTGCGGGGGTCTAGGTCTCAGGTTAACTAGTGGATGCGGATGCTG...       0.975779\n",
       "1      16  AGTACTCTTGCTCCCACACGCTCGCGCCTGGTACGTCTAAGGACGG...       0.940327\n",
       "2      95  AGTGGAATTGTACGGGGCACATCTTAGGCAGGGGTGGATGCGGCTT...       0.856257\n",
       "3      33  AGTATGTCGTCGCGTGTTGTTTCTAATCTTCGTGGCCTGTGGTGCA...       0.834777\n",
       "4      22  AGTAGTGTGTACGCAGAACCCGGGCATGATCCTGCGCGACAACTTT...       0.779282\n",
       "5      40  AGTCACTGGCCATTAGCGACGAAGTCTGTTGTCGTGGGTGCGAAGC...       0.778203\n",
       "6      20  AGTAGCGGCGAAAGAGTCGTGGGTGCGCAGGTCTGCTCGCTTGGGG...       0.776115\n",
       "7      96  AGTGGCATGTTGTGCTGTGTCGGGTCAGACAGGCATGGTGGTCAGG...       0.766534\n",
       "8       1  AAAAGCGTAAGTTGCCCCCACGTTTTTCAGCGCTGCTGCGGAAGCG...       0.746711\n",
       "9      58  AGTCGCTCGGAACGTTACAGTTCCGGGGTACAAGACGGGTTATTCT...       0.729927\n",
       "10     15  AGTACTCCCGAAGAGTACGTTATGTGTGGACTTGACCGCCTGGGGG...       0.727682\n",
       "11     37  AGTATTAACGTGGCCTACTGTTCTTACTGTCCAGCGTCGTGTTTCA...       0.709952\n",
       "12     74  AGTCTTGACCGCGGAAAACTAGGTCTTGGTCCTGTCTCAGGAGGAT...       0.702116\n",
       "13     84  AGTGCAGCAGGCCAGGGTTGGTTTAGGGCAGGCTATACGGTGCCGA...       0.697783\n",
       "14      7  AGTAAGAGGCCTGGATAAACCTGTCGGATAAGATTCGTCTACAAAT...       0.692216\n",
       "15     35  AACATGTCTCACCGTAGGCGTAAGCAACGCCAGCACACACAGTTGC...       0.668215\n",
       "16     31  AGTATGATGTTGAAAACACGAAGATTGGTCTTTTCGGGGGAAAGCC...       0.667329\n",
       "17     93  AGTGCTTAGGAGCGGGGTTTAGGGGCGCTGCGTCTGGTATCCTATG...       0.661053\n",
       "18     72  AGTCTCGCGTTTGTTTACGGGTGGTTCGCTTGTAATCGATGCGCTT...       0.659408\n",
       "19     67  AGTCTAGTTTCATGGCTTGCGGGCTAAGTGTGGAATTGTTGTAGTT...       0.657779\n",
       "20     83  AGTGATTTCTAGGTCACCTATCGTATCTGCTTCAATGATGTTATGA...       0.634959\n",
       "21     24  AACATCACAATTTTGTCATGTTATTCGCAGGAATCATTCCGCGCAT...       0.633381\n",
       "22     36  AGTATGTGGGTGGGGAGGTCAGTGTGAGGGGAGCGTGGGGATCTAT...       0.628763\n",
       "23      8  AGTAATTCTGGTTCGCCCCTGTGGGATGGTATCAAAAGAAGGATGG...       0.617448\n",
       "24     66  AGTCTAGGCTGGGGCGCCAGAAGGGCATGGTTTTGACGATGGGGTA...       0.614584\n",
       "25     77  AGTGACCAAGGCTCACGCCGGTCTGGTCGGATACAGGGTAGACGTT...       0.612849\n",
       "26      2  AACAGTGTGGCGCTGTGTGGTTTCGAGGGGACGGCACGGGGATGAA...       0.611789\n",
       "27     88  AGTGCGTCTAGTCGTTGTCGCGTGGTGGACGTGGGACCTCGGTAGG...       0.594199\n",
       "28     57  AACATTGTCTGATGATTCGAGTATACCAAGTTCGTGAAAGGTGAGG...       0.587134\n",
       "29     48  AGTCCACTAAGGAATTCCGGCTTCCAACGGATAGTTCGGCGTACTA...       0.584215\n",
       "..    ...                                                ...            ...\n",
       "70     75  AGTCTTTGGCGATCGTCGCCCCTATAGGTTGCTAAGAGGTACTGGA...       0.351753\n",
       "71     97  AGTGTACCGGCTGTATTTAAGGACCTTGTGAGCAAGTTCAAGGGGT...       0.322393\n",
       "72     30  AGTATCTGAAAGGTACGTGTTCTAGTTTAATTGGACATGCCCGAGT...       0.318473\n",
       "73     71  AGTCTCATTCCTATTTCTACGAGAGATGTTTATATCCGTGGATCGT...       0.314584\n",
       "74      6  AGTAACGGGCACAGGTGCTGCCAACATTTCTGTTTATACAAGCAGC...       0.305360\n",
       "75     45  AGTCATCTAGACTTTAATGCTTCGTTTGGCGGTTTAGCCCAATGAA...       0.294646\n",
       "76     89  AGTGCTAAAGCTGTAAATGCCTGGAATCGCAGGAAATGGTAGTATC...       0.292869\n",
       "77     62  AGTCGTGTGATGTTGGTTGGATGGGGCGATGAAGTGGAAGGTCAGA...       0.292501\n",
       "78     52  AGTCCGTTGATGTGTGTGCCTGTAATTTCGTTCACCATAGGACACA...       0.286384\n",
       "79     61  AGTCGTGGTTCACCCTGACCTGCAAAGAGTATGGATCGGGAGTAAC...       0.272403\n",
       "80     43  AGTCAGGAAAGACGCAGTCAGTTTGATTCCGTATGATACAATTGTG...       0.260749\n",
       "81     17  AGTAGAGGGTAATTCGTGGTAGTTCAACCTTGGTAGGGAGCCGTCA...       0.254779\n",
       "82     79  AACCAATTTGGTTGTAATCGTTGGCTTTCCATATGGTGTTCACCAT...       0.254244\n",
       "83     55  AGTCGATTTAGCCCTTCATCGTTCCAAGTGCGATTATGAGACGAAA...       0.253605\n",
       "84     23  AGTAGTTCATTTGGTGTTAAGATTGGCATATAGCTCAGTTCATTGG...       0.239642\n",
       "85     86  AGTGCCCTGTCTTGCTTGTTGGGCGAATATAATCTTTTTCGTGCAC...       0.235702\n",
       "86      9  AGTACAATACATGTACTAGGCCTTTTAGTTTAGTCAGTGACATATC...       0.231761\n",
       "87     99  AGTGTAGAAGAGTCTACCGGGTACCTCGTTAATCAAACAGGCCACT...       0.229215\n",
       "88     44  AGTCAGTGTTAGTGTTAGACGCTGAGCGGTTCTACAGGCTCGGTAA...       0.218834\n",
       "89     51  AGTCCGAGCTAGACTACGCTTTAAATTTGGATCAAGTTCTCGAAGT...       0.201864\n",
       "90     29  AGTATCGGTGAGTTTATTAAGGTTTTACTCTAATGTGGGGGACTAA...       0.196002\n",
       "91     47  AGTCCAAAGAGGTTCCCAGTACTGGAAAAGGGTTAGATGGGTTGAG...       0.190039\n",
       "92     27  AGTATATTAGGGGATTTTTTAACGTACTTTGATCAAGTGACTCATC...       0.189980\n",
       "93      4  AGTAAATCCTTATTTGACGATTACACACTTAACTAGCACCCCTCTT...       0.189049\n",
       "94     18  AGTAGATGATCTTCGCAAGTTGACTTATTCGCTGTTTTGGATTTGA...       0.188553\n",
       "95     85  AGTGCATCATAGGCCATCTAAAGGTGAAACTGATTTTTCGTATGTA...       0.184068\n",
       "96     65  AGTCTAGATTATTGTCACTTCTGAGGTGGTATAGCGATCCTAGCTG...       0.181779\n",
       "97     25  AGTATAGGAGTAAAACTTGTACATGAGTTTACTCATTAATTGTCTT...       0.174911\n",
       "98     21  AGTAGTAGTATCAAAGGTTATATATACACGTAGTTTGTATAACAGA...       0.166833\n",
       "99     81  AGTGACTAAGAGTGTTCTGGTAGGTTTATTGTAACCCTAAGGATTT...       0.138155\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "construct.get_predictions_for_input_file(input_seqs, model_to_use, sort_df=True, write_to_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yeast",
   "language": "python",
   "name": "yeast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
