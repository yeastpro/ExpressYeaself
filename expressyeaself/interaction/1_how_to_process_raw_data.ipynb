{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Raw Data with _ExpressYeaself_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This **interactive** notebook that will **automate** the **processing** of raw data. All you need to do is **set the parameters** that control the way in which the data is processed.  \n",
    "\n",
    "\n",
    "* If you haven't already done so, please **download the raw data** by following the installation instructions found in our [README](https://github.com/yeastpro/ExpressYeaself/blob/master/README.md).  \n",
    "\n",
    "\n",
    "* Run (using ``shift`` + ``enter``) **every cell** in this notebook from top to bottom . You'll need to **input some arguments** for some functions where instructed to before running the cell. This will involve assigning values to variables but typing some input after ``=`` signs.  \n",
    "\n",
    "\n",
    "* If an error is thrown, check your input and try to run the cell again. Make sure you've assigned the variables by typing exactly what's in the ``codeblock``. For example, for parameter 2 ``'pTpA'`` is a correct assignment but ``pTpA`` **is not**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import context\n",
    "import os\n",
    "\n",
    "process = context.process_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the paths to the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "raw_pTpA = current_directory + '/../../example/pTpA_data/raw_data_pTpA.txt.gz'\n",
    "raw_data_Abf1TATA = current_directory + '/../../example/Abf1TATA_data/raw_data_Abf1TATA.txt.gz' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the processing parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Decide what raw data you want to use. Type ``raw_pTpA`` or ``raw_Abf1TATA`` after the ``=`` sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data = raw_pTpA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Choose the scaffold type. If you chose ``raw_pTpA`` the scaffold type is ``'pTpA'`` and if you chose ``raw_Abf1TATA`` the scaffold type is ``'Abf1TATA'``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaffold_type = 'pTpA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. If you specify a value for this parameter, the sequences in your raw data file are sorted by expression level. The top and bottom percentiles of the data are then extracted and proceed with the data processing, whereas the middle portion of the data is discarded.\n",
    "    * For example, if you specify ``percentile = 0.25`` the quarter of sequences with the highest expression levels and the quarter of sequences with the lowest expression levels are extracted. The middle 50 % of data is discarded.\n",
    "    * **Why use this?** This parameter is useful for creating extremes of data based on expression level, which can be used to train a classification model. This can predict the probability that a sequence will express _high_ or express _low_.\n",
    "    * **Why not?** Is best used to train binary classification models. For a more quantitative prediction of expression level across a whole range, set this parameter to ``None``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. If (and only if) you have set a value of ``percentile`` that **is not ``None``**, choose whether or not to binarize the expression levels. This will set the expression levels of all sequences in the top pecentile to ``1`` and all the expression levels in the bottom percentile to ``0``. \n",
    "    * Highly recommended that you set ``binarize_expression_levels = True`` if you have specified a value for ``percentile``.\n",
    "    * Otherwise, set ``binarize_expression_levels = False``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarize_expression_levels = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. The raw data you have downloaded contains sequences of **variable** length, ranging from 97 to 127 nucleotides. To train a neural network model, the inputs must be encoded and all the encoded sequences must be the same length. Sequences are **automatically padded** so they are the same length. **However**, if you choose to set ``pull_only_homogeneous = True`` all the sequences that have the modal (most common) length will be pulled out. Every sequence will by definition have the same length - be _homogeneous_ - so will not need padding. For pTpA data, for instance, this is 110 nucleotides, and for Abf1TATA data this is 115 nucleotides.\n",
    "    * If you choose ``pull_only_homogeneous = False``, sequences that are shorter than the longest sequence in the file will be 'padded' to the max length. When you encode your data, the padding will be encoded as empty vectors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pull_only_homogeneous = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. The sequences in the raw data file contain '**flanking regions**'. This are short nucleotide sequences on each end of the oligonucleotide sequences found in the file that aid in the synthesis of polynucleotide sequences where nucleotides are inserted into '**scaffold sequences**'. Every sequence in each raw data file has the same flanking regions, though the flanking regions in the pTpA sequence data are **different** than those in the Abf1TATA sequence data. Here you can choose whether or not to remove these flanking regions.\n",
    "    * Recommended: ``deflank_sequences = True`` as we can remove as many constants as possible before training a model that needs to pick up on subtleties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "deflank_sequences = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Here you can choose whether or not to insert the sequences found in the raw data file into the middle of their corresponding scaffold sequences. Set ``insert_into_scaffold = True`` or ``insert_into_scaffold = False``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_into_scaffold = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Here you can choose whether or not to add extra padding to the sequences. This may be useful if you want to increase the sequence length to a particular length, but otherwise is not recommended; the automatic padding mechanism (or selecting ``pull_only_homogeneous = True`` in step 5) is usually sufficient. Set ``extra_padding = 0`` if you don't want to add extra padding, or else put in another positive integer if you do. Setting ``extra_padding = 3`` will pad sequences by an extra 3 empty nucleotides (that will be encoded as empty vectors later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_padding = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. If you have selected to use some extra padding, or have set ``pull_only_homogeneous = False`` (which automatically pads sequences), here you can choose whether that padding is added to the front (LHS) or back (RHS) of the sequences. Set ``pad_front = True`` if you want to back the front, or ``pad_front = False`` if you want to pad the back. If you have set ``pull_only_homogeneous = True`` and ``extra_padding = 0`` it doens't matter what you set this paramter to as no padding will be applied (you must still set it to something though)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_front = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. If you would like a log report of the data processing to be written to file set ``log_process_report = True``. This will write **timings** of each step and **data lost/discarded** at each stage to file, which can be found at file path ``ExpressYeaself/example/processed_data/``. It is recommended to set ``log_process_report = False`` as this information is also printed at the end of the notebook when you call the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_process_report = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. If you would like the intermediate files created at each step of the data processing to be deleted after the process is complete, set ``remove_files = True``. It is **strongly recommended** to do so. This is because we are dealing with very large files, so having files for each step will use up a lot of memory. Otherwise, set ``remove_files = False``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_files = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Finally, if you would like to create a smaller sample data file based on your processed data, then you can specify a sample size here. This will pull this many sequence and expression level data lines from your processed data file pseudo-randomly.\n",
    "    * This is useful for playing about with model architectures as a smaller data set (recommended size: ``sample_size = 10_000``) will run significantly faster.\n",
    "    * If you don't want to create a sample data file, set ``sample_size = None``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 10_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have specified all the parameters you are ready to call the function that processes the raw data. Just run the following cell and wait ~ 10 minutes (depending on computer performance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing of raw data...\n",
      "Pulling out the top and bottom percentiles...\n",
      "Binarizing expression levels...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/joe.abbott/Documents/dataScience/capstone/ExpressYeaself/expressyeaself/interaction/example/processed_data/20190613184401614474_df_to_file.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-30da8c1f9b38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                           \u001b[0mreport_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_process_report\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                           \u001b[0mremove_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremove_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                           create_sample_of_size=sample_size)\n\u001b[0m",
      "\u001b[0;32m~/Documents/dataScience/capstone/ExpressYeaself/expressyeaself/process_data.py\u001b[0m in \u001b[0;36mprocess_raw_data\u001b[0;34m(input_seqs, scaffold_type, percentile, binarize_els, homogeneous, deflank, insert_into_scaffold, extra_padding, pad_front, report_loss, report_times, remove_files, create_sample_of_size)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morganize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinarize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mprocessed_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'_els_binarized'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0minput_seqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morganize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_df_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreport_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mloss_report\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Percentile Seqs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_seq_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/dataScience/capstone/ExpressYeaself/expressyeaself/organize_data.py\u001b[0m in \u001b[0;36mwrite_df_to_file\u001b[0;34m(input_df)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# Writing to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     input_df.to_csv(absolute_path, header=None, index=None,\n\u001b[0;32m--> 182\u001b[0;31m                     sep='\\t', mode='w', columns=['seq', 'el'])\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mabsolute_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/yeast/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3018\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3019\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 3020\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3022\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/yeast/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m    156\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                                      compression=self.compression)\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/yeast/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# Python 3 and encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# Python 3 and no explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/joe.abbott/Documents/dataScience/capstone/ExpressYeaself/expressyeaself/interaction/example/processed_data/20190613184401614474_df_to_file.txt'"
     ]
    }
   ],
   "source": [
    "processed_data = process.process_raw_data(input_seqs=raw_data,\n",
    "                                          scaffold_type=scaffold_type,\n",
    "                                          percentile=percentile,\n",
    "                                          binarize_els=binarize_expression_levels,\n",
    "                                          homogeneous=pull_only_homogeneous,\n",
    "                                          deflank=deflank_sequences,\n",
    "                                          insert_into_scaffold=insert_into_scaffold,\n",
    "                                          extra_padding=extra_padding,\n",
    "                                          pad_front=pad_front,\n",
    "                                          report_loss=log_process_report,\n",
    "                                          report_times=log_process_report,\n",
    "                                          remove_files=remove_files,\n",
    "                                          create_sample_of_size=sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now you have the absolute path of the processed data you've just created; copy this, you'll need it in the next step when you build and train a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yeast",
   "language": "python",
   "name": "yeast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
